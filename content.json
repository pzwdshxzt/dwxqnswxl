{"meta":{"title":"My mother wouldn't let me play with fools.","subtitle":"When I think of you, I smile.","description":"Love and peace cosmopolitanism","author":"Huangjinxing","url":"https://www.dwxnqswxl.cn"},"pages":[{"title":"about me","date":"2018-08-22T07:36:22.000Z","updated":"2018-08-23T05:38:15.001Z","comments":false,"path":"about/index.html","permalink":"https://www.dwxnqswxl.cn/about/index.html","excerpt":"","text":"手起键落,百行代码谷歌百度,国内国外这就是我,代码搬运工若有侵权,联系我删感谢您花时间阅读我的博客，期待能与你’再见’。"},{"title":"categories","date":"2018-08-22T07:36:22.000Z","updated":"2018-08-22T09:15:28.419Z","comments":false,"path":"categories/index.html","permalink":"https://www.dwxnqswxl.cn/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-08-22T07:36:22.000Z","updated":"2018-08-22T09:15:06.107Z","comments":false,"path":"tags/index.html","permalink":"https://www.dwxnqswxl.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"HashMap（JDK1.8）源码阅读记录","slug":"YM00000001","date":"2018-08-22T03:22:41.000Z","updated":"2018-08-23T01:21:13.895Z","comments":true,"path":"2018/08/22/YM00000001/","link":"","permalink":"https://www.dwxnqswxl.cn/2018/08/22/YM00000001/","excerpt":"HashMap基于哈希表的 Map 接口的实现。此实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 此实现假定哈希函数将元素适当地分布在各桶之间，可为基本操作（get 和 put）提供稳定的性能。迭代 collection 视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）成比例。所以，如果迭代性能很重要，则不要将初始容量设置得太高（或将加载因子设置得太低）。 数据结构先看下hashmap的数据结构大概就是如图所示。table就是数组咯。链表的他们称之为桶。大于阈值就转成红黑树咯，主要是为了提高效率。使用红黑树来实现。 构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; /** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 其中最主要的是初始化的大小还有初始化填充因子static final float DEFAULT_LOAD_FACTOR = 0.75f;HashMap的容量超过当前数组长度加载因子，就会执行resize()算法比如说向水桶中装水，此时HashMap就是一个桶， 这个桶的容量就是加载容量，而加载因子就是你要控制向这个桶中倒的水不超过水桶容量的比例，比如加载因子是0.75 ，那么在装水的时候这个桶最多能装到3/4 处，超过这个比例时，桶会自动扩容。因此，这个桶最多能装水 = 桶的容量 加载因子。 12345678910111213141516/** * 获取初始值，你输入的初始值，不一定是初始化时所用的初始值。 * 为什么初始值必须是2得倍数呢，下面代码会给你解释。 * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; MAXIMUM_CAPACITY = 1&lt;&lt;30; 这样得到的始终是你输入初始值小于最小的2的次幂，也就是说比如你输入15 —&gt;&gt;1629 —&gt;&gt;3244 —&gt;&gt;64 重要函数hash()12345678910111213141516171819202122/** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */ static final int hash(Object key) &#123; int h; // 这一顿操作大概的意思就是保留了高16位的值 // 其实低16位得值也保留了下来，只要在做一次异或，值就变回来了 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125;","text":"HashMap基于哈希表的 Map 接口的实现。此实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 此实现假定哈希函数将元素适当地分布在各桶之间，可为基本操作（get 和 put）提供稳定的性能。迭代 collection 视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）成比例。所以，如果迭代性能很重要，则不要将初始容量设置得太高（或将加载因子设置得太低）。 数据结构先看下hashmap的数据结构大概就是如图所示。table就是数组咯。链表的他们称之为桶。大于阈值就转成红黑树咯，主要是为了提高效率。使用红黑树来实现。 构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; /** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 其中最主要的是初始化的大小还有初始化填充因子static final float DEFAULT_LOAD_FACTOR = 0.75f;HashMap的容量超过当前数组长度加载因子，就会执行resize()算法比如说向水桶中装水，此时HashMap就是一个桶， 这个桶的容量就是加载容量，而加载因子就是你要控制向这个桶中倒的水不超过水桶容量的比例，比如加载因子是0.75 ，那么在装水的时候这个桶最多能装到3/4 处，超过这个比例时，桶会自动扩容。因此，这个桶最多能装水 = 桶的容量 加载因子。 12345678910111213141516/** * 获取初始值，你输入的初始值，不一定是初始化时所用的初始值。 * 为什么初始值必须是2得倍数呢，下面代码会给你解释。 * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; MAXIMUM_CAPACITY = 1&lt;&lt;30; 这样得到的始终是你输入初始值小于最小的2的次幂，也就是说比如你输入15 —&gt;&gt;1629 —&gt;&gt;3244 —&gt;&gt;64 重要函数hash()12345678910111213141516171819202122/** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */ static final int hash(Object key) &#123; int h; // 这一顿操作大概的意思就是保留了高16位的值 // 其实低16位得值也保留了下来，只要在做一次异或，值就变回来了 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; public V put(K key, V value) {}123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 看下值放在哪一个table[] // 这里也有一个为什么table的大小为什么必须是2的倍数的原因 // n 是 tab的长度 那么 (n - 1) &amp; hash 的意思就是？ // 假如 长度为 16(10000) 那么 15(01111) &amp; 就得到最后hash值相当于 h &amp; (length - 1) == h % length // 这样数组也不会越界等 运算得比%运算得快 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 已经有了，就看下是放在 链表还是红黑树。 else &#123; Node&lt;K,V&gt; e; K k; //先比较s是不是在头节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //或者是红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //没办法了，只能是链表了 else &#123; for (int binCount = 0; ; ++binCount) &#123; //直接放在尾部 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表大于8个阈值直接转成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //存在一模一样的key则跳出继续 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //继续遍历 p = e; &#125; &#125; //如果找到了存放的位置 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // onlyIfAbsent为false或者旧值为null // onlyIfAbsent是传入的参数 默认w为false直接替换 if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; ++modCount; // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; public V get(Object key) {}相对于put，get就比较简单了。相对jdk1.7版本1.7 —-&gt;1.8位桶+链表 —-&gt; 位桶+链表大于阈值（8）后切换成红黑树大数据下 O(n)-&gt;&gt;O(Logn) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null : * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise * it returns &#123;@code null&#125;. (There can be at most one such mapping.) * * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to &#123;@code null&#125;. * The &#123;@link #containsKey containsKey&#125; operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */ public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //判断是不是第一个结点 是就返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 节点下面还有东西？ if ((e = first.next) != null) &#123; // 是红黑树吗？ if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //不是红黑树那你肯定是链表咯 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; resize()hashmap的扩容方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node&lt;K,V&gt;[] resize() &#123; //保存旧的 Node&lt;K,V&gt;[] oldTab = table; //保存长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //保存阈值 需要resize的阈值 int oldThr = threshold; int newCap, newThr = 0; // 之前table大小大于0 if (oldCap &gt; 0) &#123; // 之前table大于最大容量 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 阈值为最大整形 threshold = Integer.MAX_VALUE; return oldTab; &#125; // 容量翻倍，使用左移，效率更高 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // double threshold 阈值翻倍 newThr = oldThr &lt;&lt; 1; // 之前阈值大于0 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // oldCap = 0并且oldThr = 0，使用缺省值（如使用HashMap()构造函数，之后再插入一个元素会调用resize函数，会进入这一步） else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 新阈值为0 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) // 初始化table Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 之前的table已经初始化过 if (oldTab != null) &#123; // 复制元素，重新进行hash for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果链表只有一个，则直接赋值 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //红黑树啊 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //只能是链表了 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 这一顿操作之后大概就是这个过程吧 #ENDHashMap运用了许多非常巧妙的算法吧，大量的使用到了位运算，让这个结构运行更稳定更巧妙。每次看都有新收获。","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://www.dwxnqswxl.cn/categories/源码阅读/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://www.dwxnqswxl.cn/tags/HashMap/"},{"name":"源码阅读","slug":"源码阅读","permalink":"https://www.dwxnqswxl.cn/tags/源码阅读/"}]},{"title":"LinkedList（JDK1.8） 源码阅读记录","slug":"YM00000002","date":"2018-08-22T03:22:41.000Z","updated":"2018-08-23T02:55:34.254Z","comments":true,"path":"2018/08/22/YM00000002/","link":"","permalink":"https://www.dwxnqswxl.cn/2018/08/22/YM00000002/","excerpt":"","text":"LinkedList LinkedList是基于双向循环链表（从源码中可以很容易看出）实现的，除了可以当做链表来操作外，它还可以当做栈、队列和双端队列来使用。 LinkedList同样是非线程安全的，只在单线程下适合使用。 LinkedList实现了Serializable接口，因此它支持序列化，能够通过序列化传输，实现了Cloneable接口，能被克隆。 先看LinkedList数据结构 1234567891011121314/** 再看下这个节点吧 * LinkedList中的内部类 */private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 根据JDK版本的不同 ，构造方法也不同12345678910111213141516171819202122232425262728293031323334353637383940414243/** * JDK1.8 * Deque接口，Deque接口表示是一个双端队列，那么也意味着LinkedList是双端队列的一种实现， * 所以，实现了基于双端队列的所有操作。 */public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; transient int size = 0; /** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; /** * Constructs an empty list. */ public LinkedList() &#123; &#125; /** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */ public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; 1234567891011121314151617181920/** * 构造方法在1.6版本也不太一样 * 默认构造函数：创建一个空的链表 */ public LinkedList() &#123; header.next = header.previous = header; &#125; /** * 链表的表头，表头不包含任何数据。Entry是个链表类数据结构。 相当于1.8 Node */private transient Entry&lt;E&gt; header = new Entry&lt;E&gt;(null, null, null); /** * 包含“集合”的构造函数:创建一个包含“集合”的LinkedList */ public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * 因为数据结构不大一样 所以add方式也不一样 * remove方式 实现方式有一点不一样 */ /** * JDK1.8 节点Node * Links e as last element. */ void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; /** * Unlinks non-null node x. */ E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125; /** * JDK1.6 节点Entry * 将节点(节点数据是e)添加到entry节点之前。 */ private Entry&lt;E&gt; addBefore(E e, Entry&lt;E&gt; entry) &#123; // 新建节点newEntry，将newEntry插入到节点e之前；并且设置newEntry的数据是e Entry&lt;E&gt; newEntry = new Entry&lt;E&gt;(e, entry, entry.previous); newEntry.previous.next = newEntry; newEntry.next.previous = newEntry; // 修改LinkedList大小 size++; // 修改LinkedList的修改统计数：用来实现fail-fast机制。 modCount++; return newEntry; &#125; /** * 将节点从链表中删除 */ private E remove(Entry&lt;E&gt; e) &#123; if (e == header) throw new NoSuchElementException(); E result = e.element; e.previous.next = e.next; e.next.previous = e.previous; e.next = e.previous = null; e.element = null; size--; modCount++; return result; &#125; ##Java 集合中常见 checkForComodification()方法的作用? modCount和expectedModCount作用? Node的查找加速12345678910111213141516171819202122/** * 源码中先将index与长度size的一半比较，if index &lt; (size &gt;&gt; 1)，就只从位置0往后遍历到位置index处， * 而如果index &gt; (size &gt;&gt; 1)，就只从位置size往前遍历到位置index处。 * 这样可以减少一部分不必要的遍历，从而提高一定的效率（实际上效率还是很低）。 * JDK1.8这里用的是位运算 ， 而JDK1.6 用的是判断index&lt;size/2 * Returns the (non-null) Node at the specified element index. */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 每次看都有新发现，都会更新记录！","categories":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://www.dwxnqswxl.cn/categories/源码阅读/"}],"tags":[{"name":"源码阅读","slug":"源码阅读","permalink":"https://www.dwxnqswxl.cn/tags/源码阅读/"},{"name":"LinkedList","slug":"LinkedList","permalink":"https://www.dwxnqswxl.cn/tags/LinkedList/"}]}]}